{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce77b3b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Differential equation resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f41a263",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook is inspired by the one in the Perceval documentation. It implements more ways to compute the resolution of a DE, including closer to the behavior of a real photonic chip ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a2333",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c3914",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import perceval as pcvl\n",
    "import perceval.lib.phys as phys\n",
    "import numpy as np\n",
    "from math import comb\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import time\n",
    "import os\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# If not a notebook : from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import scipy.signal as signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d25b1c6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**True if we launch single computations during the notebook execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2026e4b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set to True to launch single computations. Useful for testing particular settings\n",
    "launch_single_computation = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fb0db3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Differential equation and parameters** : defined only once to make results comparable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03342d36",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Differential equation parameters\n",
    "lambd = 8\n",
    "kappa = 0.1\n",
    "\n",
    "def F(u_prime, u, x):       # DE: F(u_prime, u, x) = 0\n",
    "    # Must work with numpy arrays\n",
    "    return (u_prime + lambd * u * (kappa + np.tan(lambd * x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95885d6a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Boundary condition (f(x_0)=f_0)\n",
    "x_0 = 0\n",
    "f_0 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af9cb95",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The solution of this differential equation is $f(x) = f_0  \\exp(-\\kappa \\lambda x)  \\cos(\\lambda x)$ (must be changed in the documentation notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f60c2f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Differential equation's exact solution - for comparison\n",
    "def u(x):\n",
    "    return np.exp(- kappa*lambd*x)*np.cos(lambd*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2448438d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Modeling parameters\n",
    "n_grid = 50    # number of grid points of the discretized differential equation\n",
    "range_min = 0  # minimum of the interval on which we wish to approximate our function\n",
    "range_max = 1  # maximum of the interval on which we wish to approximate our function\n",
    "X = np.linspace(range_min, range_max, n_grid)  # Optimisation grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78462bb1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters of the quantum machine learning procedure\n",
    "eta = 5                   # weight granted to the initial condition\n",
    "a = 10                    # Approximate initial boundaries of the interval that the image of the trial function can cover\n",
    "alpha = 0.0005            # Penality applied to the lambda coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc4ec2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Threshold detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4db2ff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we create the function that will be used to compute the different probabilities in a generic case. It will be used for almost all the detection processes using a threshold detection.\n",
    "\n",
    "The construction method uses the binary representation of a mode (1 if there is at least one photon, 0 else) to represent each mode by a single index. Equivalent modes share the same index.\n",
    "\n",
    "With this detection method, we need $2^m$ weights if $N = m$. In fact, if the source is perfect, we should need only $2^m - 1$ weights as the 0 binary representation doesn't match any mode, but its easier to keep the same computation. \n",
    "\n",
    "If $N \\ne m$, then more binary representations will not match anything (for example, if N = 2 and m = 4, the number 0111 will not appear). Thus, the computation could be quicker as it would lead to many $0*weight$. In fact, if $m = 2N$, the number of needed parameters is $\\sum_{n = 0}^{n = N} {m\\choose n} = 2^{m-1} + \\frac{1}{2} {m\\choose N}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46198698",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_threshold_indexes(m):\n",
    "    \"\"\"\n",
    "    input : m[int] - the number of modes\n",
    "    return : None\n",
    "    \n",
    "    Create an auxiliary list containing for each circuit output the index of the threshold probability list\n",
    "    where the output probability must be summed\n",
    "    \n",
    "    Only used during the initialisation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Here we create a list containing for each state the index in the threshold list that it corresponds to (i.e. where the probability will be summed).\n",
    "    global threshold_indexes\n",
    "    threshold_indexes = []\n",
    "    \n",
    "    #Necessary, else with an imperfect source, some states wouldn't be considered, even if the computation would not raise an error\n",
    "    if not as_imperfect_source:\n",
    "        \n",
    "        sim = simulator_backend(pcvl.Matrix.random_unitary(m))\n",
    "        sim.compile(input_state)\n",
    "        \n",
    "        iterator = sim.allstate_iterator(input_state)\n",
    "    \n",
    "    else:\n",
    "        src = pcvl.Source(brightness=0, purity = purity) # The only goal here is to get all possible states\n",
    "        \n",
    "        processor = create_processor(src, phys.Unitary(pcvl.Matrix.random_unitary(m)), [1]*N+[0]*(m-N))\n",
    "        iterator = get_all_processor_states(processor)\n",
    "    \n",
    "    for state in iterator:\n",
    "        binary = []\n",
    "\n",
    "        for mode in range(m):\n",
    "            if state[mode] == 0:\n",
    "                binary.append(0)\n",
    "            else:\n",
    "                binary.append(1)\n",
    "\n",
    "        i = sum(val*(2**idx) for idx, val in enumerate(reversed(binary))) # Binary to decimal conversion\n",
    "        \n",
    "        if not method == \"pseudo PNR\" or state in B_useful_states:\n",
    "\n",
    "            threshold_indexes.append(i)\n",
    "    \n",
    "    # Here we flatten the list so every index from 0 to sum^{N} (comb(m,n)) is represented, avoiding holes\n",
    "    if m != N:\n",
    "        mod_index = 0\n",
    "        stop = max(threshold_indexes) + 1\n",
    "        for cur_index in range(stop):\n",
    "            l = [mod_index if item == cur_index else item for item in threshold_indexes]\n",
    "            # If the new list is different, \n",
    "            if l != threshold_indexes:\n",
    "                threshold_indexes = l\n",
    "                mod_index += 1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6cd46c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def threshold_prob(all_prob):\n",
    "    \"\"\"\n",
    "    input : all_prob[list] - the list of the probabilities given by the circuit\n",
    "    output : np.array containing the threshold probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    sum_prob = np.zeros(fock_dim)\n",
    "            \n",
    "    for i in range(len(threshold_indexes)):\n",
    "        sum_prob[threshold_indexes[i]] += all_prob[i]\n",
    "        \n",
    "    return sum_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9a0539",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## PNR computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027a63b3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We try to upgrade our approximation by adding beam splitters at the end of the circuit to have a chance to separate the photons when there are several on the same mode. We double the number of modes to have empty modes at the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1958c5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The computation now use both threshold detection and a bigger circuit to separate photons at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f881077d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We define a way to create our circuit separator that will come after the main circuit.\n",
    "\n",
    "*Update* : This function is now only used to display, as a N mode circuit is now used in the computation; the beam splitters are applied in post-processing (see the computation paragraph below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aefbcd7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This function is only used to display the circuit, not in the calculation\n",
    "def construct_separators(c):\n",
    "\n",
    "    # First, we need to permutate our modes (it is equivalent to permuting lines and columns in our first matrix)\n",
    "    perm =[]\n",
    "    for mode in range(m):\n",
    "        if mode < N:\n",
    "            perm.append(2*mode)\n",
    "        else:\n",
    "            perm.append(2 * mode + 1 - 2 * N)\n",
    "\n",
    "    c //= phys.PERM(perm)\n",
    "\n",
    "    # We add BS between the first modes of the circuit and the unused modes\n",
    "    for mode in range(N):\n",
    "        c //= (2*mode, phys.BS())\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5719ce4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Computation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ccf9af",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The method used to calculate all the probabilities for a $2N$ modes beam splitting circuit $\\mathcal B$ receiving inputs from a $N$ modes circuit $\\mathcal A$ is the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68566399",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If two modes $(2k, 2k+1)$ from $\\mathcal B$ have $n_1$ and $n_2$ photons, then the only possibility to have this output is that the $k^{th}$ mode from $\\mathcal A$ had $n_1 + n_2$ photons.\n",
    "\n",
    "Since we want to be able to consider only the probability list (easier for computation than considering the states), we can create an auxiliary list called *pi_factors* containing for each output mode of $\\mathcal B$ the index of the corresponding output mode in $\\mathcal A$ and the probability to get this $\\mathcal B$ state from the $\\mathcal A$ state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec69365",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_pi_factors(N):\n",
    "    \"\"\"\n",
    "    input : N[int] - the number of photons\n",
    "    Returns : None\n",
    "    \n",
    "    Creates a list allowing to get the probabilities for a 2N modes circuit from a N modes circuit using beam splitters\n",
    "    \n",
    "    Support for reflexivity has not been fully implemented yet\n",
    "    \"\"\"\n",
    "    # We first create a matrix containing the probabilities to get i photons in the 2k mode of B from n photons in the k mode of A\n",
    "    probs = np.zeros((N+1,N+1))\n",
    "    \n",
    "    \n",
    "    # We can only have up to N photons in one A mode\n",
    "    for n in range(N+1):  \n",
    "        for i in range(n+1):\n",
    "            # It is much faster to use a direct formula, and more precise in term of float operation\n",
    "            probs[n, i] = comb(n, i) * R ** i * (1-R) ** (n-i)\n",
    "    \n",
    "    \n",
    "    # Now we can create our list\n",
    "    if not as_imperfect_source:\n",
    "        \n",
    "        sB = simulator_backend(pcvl.Matrix.random_unitary(2*N))\n",
    "        sA = simulator_backend(pcvl.Matrix.random_unitary(N))\n",
    "        \n",
    "        input_state = pcvl.BasicState([N, 0]) # We input N photons, the goal is to have all the outputs with N photons\n",
    "        \n",
    "        B_iterator = sB.allstate_iterator(input_state)\n",
    "        A_iterator = list(sA.allstate_iterator(input_state))\n",
    "              \n",
    "    else:\n",
    "        src = pcvl.Source(brightness=0, purity = purity) # The only goal here is to get all possible states\n",
    "\n",
    "        A_processor = create_processor(src, phys.Unitary(pcvl.Matrix.random_unitary(N)), [1]*N)\n",
    "        A_iterator = get_all_processor_states(A_processor)\n",
    "        \n",
    "        B_processor = create_processor(src, phys.Unitary(pcvl.Matrix.random_unitary(2*N)), [1]*N + [0]*N)\n",
    "        B_iterator = get_all_processor_states(B_processor)\n",
    "        \n",
    "        \n",
    "        \n",
    "    global pi_factors\n",
    "    pi_factors = []\n",
    "    \n",
    "    \n",
    "    global B_useful_states\n",
    "    B_useful_states = []\n",
    "\n",
    "    # B_state has at most N photons\n",
    "    for B_state in B_iterator:      \n",
    "        # If we do a post selection and all_photons are not seen, we must not register that state\n",
    "        if (method != \"post selection\" or all_photons_seen(B_state)):\n",
    "        \n",
    "            A_state = []\n",
    "            p = 1\n",
    "            must_register = True\n",
    "            for k in range(0, 2*N, 2):\n",
    "                i = B_state[k]                \n",
    "                n = i + B_state[k+1]\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                This part needs to be adapted to different values of R\n",
    "                It is true only for R = .5\n",
    "                \n",
    "                It had been implemented because for R = .5, we always have some probabilities that are equal, leading to bad results.\n",
    "                For other values of R, this still has to be evaluated.\n",
    "                \"\"\" \n",
    "                # If we can see photons in only one of the two modes, it is equivalent to consider only the (n, 0) one with twice the probability\n",
    "                if i == 0 and n != 0:\n",
    "                    p = 2\n",
    "                if i == n and i != 0: # ie B_state[k+1] == 0 and the state is not [0,0]\n",
    "                    must_register = False\n",
    "             \n",
    "                p *= probs[n, i]\n",
    "                A_state.append(n)\n",
    "\n",
    "                \n",
    "                \n",
    "            if must_register:\n",
    "                B_useful_states.append(B_state)\n",
    "                A_state = pcvl.BasicState(A_state)\n",
    "                index = 0\n",
    "\n",
    "                \n",
    "                # We now need to find the index in the A circuit that corresponds to this state\n",
    "                for state in A_iterator:\n",
    "                    if state == A_state:\n",
    "                        pi_factors.append((index, p))\n",
    "                        # We can break since it can only appear once\n",
    "                        break\n",
    "\n",
    "                    index += 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99744182",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we just have to use this prepared list to compute the probabilities given the list of probabilities from $\\mathcal A$. Note these are generic probabilities, so if we want to apply a threshold, it must be done after this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65504e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_all_probs(A_probs):  \n",
    "    probs = []\n",
    "    \n",
    "    for (A_state_index, prob) in pi_factors:\n",
    "        probs.append(A_probs[A_state_index] * prob)\n",
    "        \n",
    "    return np.array(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6e90ec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We try to speed up the computation by avoiding the use of an intermediate list in case of PNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c752c7f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_PNR_probs(A_probs):\n",
    "    sum_prob = np.zeros(fock_dim)    \n",
    "    \n",
    "    for i in range(len(threshold_indexes)):\n",
    "        sum_prob[threshold_indexes[i]] += A_probs[pi_factors[i][0]] * pi_factors[i][1]\n",
    "        \n",
    "    return sum_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e48ba9b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Post selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b36d83",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will use a different way to compute the probabilities compared to in the non-selecting process. In fact, because we only consider the states having at most 1 photon for each output, each binary representation will only point to 1 state. Thus, we just have to remember for each ponderation the corresponding state, allowing us not to visit all the states. This gives us ${m \\choose N}$ vectors to verify. This quantity doesn't change if the source isn't perfect.\n",
    "\n",
    "Because we only put useful states in the *pi_factors* list, we do not have to apply a threshold computation on this (I'm not sure if this is true when we select states having at least $n$ photons with $n \\ne N$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64242920",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def all_photons_seen(state):\n",
    "    # Count how many modes have exactly 1 photon\n",
    "    mode_count = sum([1 for mode in state if mode == 1])\n",
    "    \n",
    "    return (mode_count == N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca12544",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imperfect source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a20bdf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will now try our different learning processes with an imperfect source. Since the source is the same for all input mode, we first define a function to define easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7946a201",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_processor(source, circuit, input_modes):\n",
    "    # input_modes[i] == 1 if the ith mode has a source\n",
    "    inputs = dict()\n",
    "    for i in range(len(input_modes)):\n",
    "        if input_modes[i] == 1:\n",
    "            inputs[i] = source\n",
    "    \n",
    "    return pcvl.Processor(inputs, circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ebd9e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_processor_probabilities(processor):\n",
    "    # Returns a numpy array with the probabilities of the output states\n",
    "    _, output_distribution = processor.run(simulator_backend)\n",
    "    \n",
    "    items = output_distribution.items()\n",
    "    \n",
    "    all_prob = np.array([prob for _, prob in items])\n",
    "        \n",
    "    return all_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80078849",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_processor_states(processor):\n",
    "    # Returns a numpy array with the probabilities of the output states\n",
    "    _, output_distribution = processor.run(simulator_backend)\n",
    "    \n",
    "    items = output_distribution.items()\n",
    "    \n",
    "    # state is a StateVector, so we need to extract the only BasicState that is here\n",
    "    all_states = [state[0] for state, _ in items]\n",
    "    \n",
    "    return all_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1b128b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imprecision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa851827",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It is impossible to be as precise as we want on a real chip. Computation show that the imprecision is $\\sqrt N \\Delta \\theta$. We will use a round effect to take this into account, as the imprecision is always the same for a given voltage input.\n",
    "\n",
    "An imprecision of $\\Delta \\theta$ will also be introduced in the definition of x (which is concretely an angle for a phase shifter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48219a6d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def round_imprecision(x, imprecision):\n",
    "    # Can take numpy arrays\n",
    "    if imprecision == 0:\n",
    "        return x\n",
    "    else:\n",
    "        return imprecision * np.round(x / imprecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e475da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def imprecise_matrix(parameters, delta_theta):\n",
    "    U = pcvl.Matrix.random_unitary(N, parameters)\n",
    "    \n",
    "    # sqrt(2) because our imprecision is in norm, while round acts on real and imag values\n",
    "    total_imprecision = delta_theta / np.sqrt(2)  \n",
    "\n",
    "    \n",
    "    U = round_imprecision(U, total_imprecision) \n",
    "\n",
    "    # We need to make the noised matrix unitary\n",
    "    return pcvl.Matrix.random_unitary(N, parameters = np.concatenate((np.real(U).reshape(N2), np.imag(U).reshape(N2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b89c677",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since we now have a huge step to calculate the gradient for the different parameters (we need to see a difference to optimise), we try to add a second step in which we optimise the ponderations while leaving the parameters unchanged. The best would be to do both at the same time, but it would lead to too many iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900f1269",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After some tries, it is so efficient that I decided to use that second step first and whatever the parameters are (this computation has been moved to the Computation section)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc27fb2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4505e44a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since we cannot evaluate the probabilities with a 100% accuracy, we need to simulate samples that we will observe on a real chip from the distribution that is computed from Perceval. If the number of samples is *huge* (more than 100), then the second version of the function must be used, due to computation time (just change the order of the cells when executing all). For the second version, the sampling is estimated through the variance in the number of states got."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5816ea",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The probability to get $k$ times a state with a probability $p$ for one experiment follows the binomial law $\\mathfrak{B} (n_{photons}, p)$. Thus, the standard deviation is $\\sqrt{n_{photons} p (1-p)}$, so the probability distribution that we get has a standard deviation of $\\sqrt{\\frac{p (1-p)}{n_{photons}}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526057aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# First version : true sampling, very long due to the finite difference method to evaluate the gradient. Time in O(N_samples * len(probs))\n",
    "def get_samples(N_samples, probs):\n",
    "    \n",
    "    # No sampling, get the full distribution\n",
    "    if N_samples == 0:\n",
    "        return probs\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    \n",
    "    # Generates N_samples indexes with the distribution probs    \n",
    "    choosen = rng.choice(len(probs), N_samples, p = probs)\n",
    "    \n",
    "    observed = np.array([sum(1 for i in range(N_samples) if choosen[i] == n) for n in range(len(probs))])\n",
    "        \n",
    "    return observed / N_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c2628",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Second version : distribution sampling, constant time whatever N_samples is\n",
    "def get_samples(N_samples, probs):\n",
    "    \n",
    "    # No sampling, get the full distribution\n",
    "    if N_samples == 0:\n",
    "        return probs\n",
    "    \n",
    "    rng = np.random.normal(scale = np.sqrt(probs * (1 - probs) / N_samples))\n",
    "    \n",
    "     \n",
    "    observed = probs + rng\n",
    "    \n",
    "    # Renormalise the probabilities\n",
    "    observed /= sum(observed)\n",
    "        \n",
    "    return observed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5808c9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the case we are conserving the global distribution probability, we need to retrieve the samples for each probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bc48b9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_samples(N_samples, all_probs):\n",
    "    # La construction a la même structure que celle de get_final_probs\n",
    "    probs = []\n",
    "    \n",
    "    for prob in all_probs:\n",
    "        probs.append(get_samples(N_samples, prob))\n",
    "        \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1c3884",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We try to avoid problems in the computation due to the noise by applying a noise filter. This noise filter adapt to our grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a7e1b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def noise_filter(Y):\n",
    "    # For now, we use default parameter. This must be changed later with global parameters\n",
    "    order = 2\n",
    "    Wn = 0.17\n",
    "      \n",
    "    b, t = signal.butter(order, Wn)     \n",
    "    return signal.filtfilt(b, t, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234d13ec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Photon loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eb102a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now consider that photons can be lost in the circuit or not detected. We represent this loss as a probability $p$ for each photon not to be detected at the end, without repercussion on the internal behaviour of the chip."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32097e05",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If we consider a mode $i$ having $n_i$ photons after the computation, thus the probability to get $k_i$ photons on this mode after the loss is ${n_i \\choose k_i} p^{n_i-k_i}(1-p)^{k_i}$.\n",
    "\n",
    "Then, the probability to get a given state is $ p^{N - k} (1-p)^{k} \\prod^{m}_{i = 1} {n_i \\choose k_i}$ with $k = \\sum k_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870938ca",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now create a list containing for each outcome of the imperfect device the list of the indexes of the interesting outcomes of the perfect device with their associated probability. If we are interested in a threshold detection, we can already apply it, speeding up the computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ffac60",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*In the case we are performing a pseudo PNR or a post selection method, the probability of losing the photons on the $N*N$ circuit is conserved on the $2N*2N$ circuit.* Thus, we can perform this computation before simulating the $2N*2N$ circuit.\n",
    "\n",
    "**Proof:** let's consider one mode of the $N*N$ circuit $\\mathcal A$. If there is $n$ photons on this mode, the probability to lose $k$ photons is ${n \\choose k} q_{\\mathcal A}^{n-k}(1-q_{\\mathcal A})^{k}$ with $q_{\\mathcal A} = 1-p_{\\mathcal A}$ if there is no beam splitter after. \n",
    "\n",
    "Now let's consider the two associated modes after the beam splitter (circuit $\\mathcal B$) with a reflexivity $R$. If the mode $\\mathbb 1$ gets $n_1$ photons, then the mode $\\mathbb 2$ gets $n - n_1$ photons. By the same way, if the mode $\\mathbb 1$ loses $k_1$ photons, then the mode $\\mathbb 2$ loses $k - k_1$ photons. \n",
    "\n",
    "Furthermore, in a general case, the probability that the mode $\\mathbb 1$ loses $k_1$ photons knowing it has $n_1$ photons and the mode $\\mathbb 2$ loses $k_2$ photons knowing it has $n_2$ photons is $$\n",
    "\\mathcal P ((\\mathbb{1}.k =  k_1) \\cap (\\mathbb{2}.k =  k_2) | \\mathbb{1}.n = n_1, \\mathbb{2}.n = n_2) = {n_1 \\choose k_1} q_{\\mathcal B}^{n_1-k_1}(1-q_{\\mathcal B})^{k_1} * {n_2 \\choose k_2} q_{\\mathcal B}^{n_2-k_2}(1-q_{\\mathcal B})^{k_2}\n",
    "$$\n",
    "\n",
    "where $q_{\\mathcal B}$ is the known photon loss. The goal here is to express $q_{\\mathcal B}$ as a function of $q_{\\mathcal A}$. The previous equation rewrites in our case as \n",
    "$$\n",
    "\\mathcal P ((\\mathbb{1}.k = k_1) \\cap (\\mathbb{2}.k =  k - k_1) | \\mathbb{1}.n = n_1, \\mathbb{2}.n = n - n_1) = {n_1 \\choose k_1} q_{\\mathcal B}^{n_1-k_1}(1-q_{\\mathcal B})^{k_1} * {n - n_1 \\choose k - k_1} q_{\\mathcal B}^{n - n_1 - k + k_1}(1-q_{\\mathcal B})^{k - k_1}\n",
    "$$\n",
    "\n",
    "Now we have for the total loss \n",
    "$$\n",
    "\\mathcal P (\\mathbb{1}.k + \\mathbb{2}.k = k | \\mathbb{1}.n = n_1, \\mathbb{2}.n = n - n_1) = \\sum_{k_1 = 0}^{n_1} \\mathcal P ((\\mathbb{1}.k = k_1) \\cap (\\mathbb{2}.k =  k - k_1) | \\mathbb{1}.n = n_1, \\mathbb{2}.n = n - n_1) \n",
    "$$\n",
    "\n",
    "Then setting $n_1$ as an unknown gives\n",
    "$$\n",
    "\\mathcal P (\\mathbb{1}.k + \\mathbb{2}.k = k | \\mathbb{1}.n + \\mathbb{2}.n = n) = \\sum_{n_1 = 0}^n \\sum_{k_1 = 0}^{n_1} \\mathcal P ((\\mathbb{1}.k = k_1) \\cap (\\mathbb{2}.k =  k - k_1) | \\mathbb{1}.n = n_1, \\mathbb{2}.n = n - n_1)\n",
    "* \\mathcal P (\\mathbb{1}.n = n_1 | \\mathbb{1}.n + \\mathbb{2}.n = n)\n",
    "$$\n",
    "\n",
    "But as there is a beam splitter with no photon on the second mode, this gives us $\\mathcal P (\\mathbb{1}.n = n_1 | \\mathbb{1}.n + \\mathbb{2}.n = n) = {n \\choose n_1} R^{n_1} (1-R)^{n - n_1}$\n",
    "\n",
    "Finally, we get \n",
    "$$\n",
    "\\mathcal P (\\mathbb{1}.k + \\mathbb{2}.k = k | \\mathbb{1}.n + \\mathbb{2}.n = n) = \\sum_{n_1 = 0}^n \\sum_{k_1 = 0}^{n_1} {n_1 \\choose k_1} q_{\\mathcal B}^{n_1-k_1}(1-q_{\\mathcal B})^{k_1} * {n - n_1 \\choose k - k_1} q_{\\mathcal B}^{n - n_1 - k + k_1}(1-q_{\\mathcal B})^{k - k_1} * {n \\choose n_1} R^{n_1} (1-R)^{n - n_1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathcal P (\\mathbb{1}.k + \\mathbb{2}.k = k | \\mathbb{1}.n + \\mathbb{2}.n = n) = q_{\\mathcal B}^{n - k} (1-q_{\\mathcal B})^{k} \\sum_{n_1 = 0}^n \\sum_{k_1 = 0}^{n_1} {n_1 \\choose k_1} {n - n_1 \\choose k - k_1} {n \\choose n_1} R^{n_1} (1-R)^{n - n_1}\n",
    "$$\n",
    "\n",
    "With the following code (a written proof could be provided later), we observe that \n",
    "$$\n",
    "\\sum_{n_1 = 0}^n \\sum_{k_1 = 0}^{n_1} {n_1 \\choose k_1} {n - n_1 \\choose k - k_1} {n \\choose n_1} R^{n_1} (1-R)^{n - n_1} = {n \\choose k}\n",
    "$$\n",
    "\n",
    "Finally, this gives us the equivalence of the model between a loss at the end of $\\mathcal A$ and at the end of $\\mathcal B$.\n",
    "$$\n",
    "{n \\choose k} q_{\\mathcal A}^{n-k}(1-q_{\\mathcal A})^{k} = {n \\choose k} q_{\\mathcal B}^{n - k} (1-q_{\\mathcal B})^{k}\n",
    "$$\n",
    "\n",
    "with $q_{\\mathcal A} = q_{\\mathcal B}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb3397c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N = 8\n",
    "k = 5\n",
    "R = .4\n",
    "\n",
    "def my_comb(n, k):\n",
    "    if k<0:\n",
    "        return 0\n",
    "    else:\n",
    "        return comb(n, k)\n",
    "\n",
    "print(\"left side =\", sum(comb(n1, k1) * my_comb(N - n1, k - k1) * comb(N, n1) * R**n1 * (1-R)**(N-n1) for n1 in range(N+1) for k1 in range(n1+1)))\n",
    "\n",
    "print(\"right side =\", comb(N, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ec0c37",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_photon_loss(m, N):\n",
    "    # First, we compute all the necessary powers of photon_loss\n",
    "    p_powers = [1]\n",
    "    q_powers = [1]\n",
    "    for n in range(N):\n",
    "        p_powers.append(p_powers[-1] * photon_loss)\n",
    "        q_powers.append(q_powers[-1] * (1 -photon_loss))\n",
    "        \n",
    "\n",
    "    # Now we can create our list\n",
    "    \n",
    "    # Creates an imperfect source\n",
    "    source = pcvl.Source(brightness= 1 - photon_loss)\n",
    "    \n",
    "    # We create an input state iterator\n",
    "    if not use_imperfect_source:\n",
    "        sB = simulator_backend(phys.Unitary(pcvl.Matrix.random_unitary(m)))\n",
    "        input_state = pcvl.BasicState([N, 0]) # We input N photons, the goal is to have all the output with N photons\n",
    "        \n",
    "        # list is necessary to reset the iterator on each iteration\n",
    "        B_iterator = list(sB.allstate_iterator(input_state))\n",
    "    \n",
    "    else:\n",
    "        B_processor = create_processor(source, phys.Unitary(pcvl.Matrix.random_unitary(m)), [1]*N + [0] * (m-N))\n",
    "        B_iterator = get_all_processor_states(B_processor)\n",
    "    \n",
    "    # In any case, the target will have the same states than if the source is imperfect\n",
    "    src = pcvl.Source(brightness=0, purity = purity) # The only goal here is to get all possible states \n",
    "    A_processor = create_processor(src, phys.Unitary(pcvl.Matrix.random_unitary(m)), [1]*N + [0] * (m-N))\n",
    "    A_iterator = get_all_processor_states(A_processor)\n",
    "    \n",
    "    \n",
    "    global p_loss_list\n",
    "    p_loss_list = []\n",
    "    \n",
    "    \n",
    "    for A_state in A_iterator:\n",
    "        used_states = []\n",
    "        \n",
    "        k = A_state.n\n",
    "        \n",
    "        index = 0\n",
    "            \n",
    "        for B_state in B_iterator:\n",
    "            \n",
    "            # Check whether the target state can be reached from the B state\n",
    "            if np.all([A_state[i] <= B_state[i] for i in range(m)]):\n",
    "                n = B_state.n   # Useful if the main source is not perfect\n",
    "                \n",
    "                prob = p_powers[n - k] * q_powers[k]\n",
    "                prob *= np.prod([comb(B_state[i], A_state[i]) for i in range(m)])\n",
    "                \n",
    "                used_states.append((index, prob))\n",
    "                \n",
    "            index += 1\n",
    "        \n",
    "        p_loss_list.append(used_states.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ece784",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_photon_loss(probs):\n",
    "    final_probs = np.zeros(len(p_loss_list))\n",
    "    \n",
    "    for i in range(len(p_loss_list)):\n",
    "        final_probs[i] = sum(p_loss_list[i][j][1] * probs[p_loss_list[i][j][0]] for j in range(len(p_loss_list[i])))\n",
    "        \n",
    "    return final_probs    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cc2950",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Generic functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65067238",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Because the computation is similar in every case, we define generic functions that will be defined with a *method*, so we can compute all the tries more easily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9e111",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828dfd6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tuple_to_dict(tpl):\n",
    "    # tpl is of the form (key, value, ...)\n",
    "    \n",
    "    # We use a default dictionnary for when a parameter doesn't appear\n",
    "    dictionnary = {\"method\" : None, \"N\" : 0, \"imprecision\" : 0, \"samples\" : 0, \"photon loss\" : 0, \"brightness\" : 1, \"purity\" : 1}\n",
    "    \n",
    "    for k in range(0, len(tpl), 2):\n",
    "        dictionnary[tpl[k]] = tpl[k+1]\n",
    "        \n",
    "    if \"R\" not in dictionnary.keys() and dictionnary[\"method\"] in [\"pseudo PNR\", \"post selection\"]:\n",
    "        dictionnary[\"R\"] = 0.5\n",
    "        \n",
    "    return dictionnary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612b8c6b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a951ffe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_fock_dim(m, N, method):\n",
    "    if method == \"real solving\" or method == \"fixed ponderations\":\n",
    "        if as_imperfect_source: # We must then consider all cases when less than N photons are detected\n",
    "            return sum([comb(n + m - 1, n) for n in range(N+1)])\n",
    "        return comb(N + m - 1, N)\n",
    "    \n",
    "    elif method == \"threshold\":\n",
    "        return 2**m\n",
    "    \n",
    "    elif method == \"pseudo PNR\":\n",
    "        #return 2**(m-1) + comb(m, N) // 2  # Used before the elimination of the 0s of threshold_indexes\n",
    "        return max(threshold_indexes) + 1\n",
    "    \n",
    "    elif method == \"post selection\":\n",
    "        #return comb(m, N)\n",
    "        return len(pi_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc524801",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def initiate(param_dict, display = True):   \n",
    "    # display:bool - if the circuit has to be displayed\n",
    "    \n",
    "    \n",
    "    # First part : retrieve the parameters from the dictionnary and set them as global variables \n",
    "    global method\n",
    "    method = param_dict[\"method\"]\n",
    "        \n",
    "    global N\n",
    "    global m\n",
    "    N = param_dict['N']              # Number of photons\n",
    "    \n",
    "    global R\n",
    "    R = .5   \n",
    "    if method == \"pseudo PNR\" or method == \"post selection\":\n",
    "        m = 2 * N\n",
    "        if \"R\" in param_dict.keys():\n",
    "            R = param_dict[\"R\"]\n",
    "    else:\n",
    "        m = N\n",
    "    \n",
    "    # N2 will be used frequently\n",
    "    global N2\n",
    "    N2 = N ** 2\n",
    "    \n",
    "    \n",
    "    \n",
    "    global use_imperfect_source\n",
    "    use_imperfect_source = False\n",
    "    \n",
    "    global brightness\n",
    "    if \"brightness\" in param_dict.keys():   \n",
    "        brightness = param_dict[\"brightness\"]\n",
    "        if brightness != 1:\n",
    "            use_imperfect_source = True\n",
    "    else:\n",
    "        brightness = 1\n",
    "    \n",
    "    global purity\n",
    "    if \"purity\" in param_dict.keys():   \n",
    "        purity = param_dict[\"purity\"]\n",
    "        if purity != 1:\n",
    "            use_imperfect_source = True\n",
    "    else:\n",
    "        purity = 1\n",
    "            \n",
    "            \n",
    "    if use_imperfect_source:\n",
    "        global source\n",
    "        source = pcvl.Source(brightness=brightness, purity=purity)\n",
    "    \n",
    "    \n",
    "      \n",
    "    global imprecision\n",
    "    if \"imprecision\" in param_dict.keys():     \n",
    "        imprecision = param_dict[\"imprecision\"]\n",
    "    else:\n",
    "        imprecision = 0\n",
    "        \n",
    "    \n",
    "    global samples\n",
    "    if \"samples\" in param_dict.keys():     \n",
    "        samples = param_dict[\"samples\"]\n",
    "    else:\n",
    "        samples = 0\n",
    "     \n",
    "    \n",
    "    global as_imperfect_source   # Means that the output can have photon loss\n",
    "    as_imperfect_source = use_imperfect_source\n",
    "                \n",
    "    global photon_loss\n",
    "    if \"photon loss\" in param_dict.keys():     \n",
    "        photon_loss = param_dict[\"photon loss\"]\n",
    "        if photon_loss != 0:\n",
    "            as_imperfect_source = True\n",
    "    else:\n",
    "        photon_loss = 0\n",
    "\n",
    "    ##############################################################################################################\n",
    "    # Second part : initialise the computation variables\n",
    "    \n",
    "    # Input state with N photons and m modes\n",
    "    global input_state\n",
    "    input_state = pcvl.BasicState([1]*N+[0]*(m-N))\n",
    "    \n",
    "    global simulator_backend\n",
    "    simulator_backend = pcvl.BackendFactory().get_backend(\"SLOS\")\n",
    "    \n",
    "    # Create a simulator of the good size, useless if there is an imperfect source (another object will be used)\n",
    "    if not use_imperfect_source:           \n",
    "        global s1\n",
    "        s1 = simulator_backend(pcvl.Matrix.random_unitary(N))\n",
    "        s1.compile(input_state)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # If necessary, compute the calculus auxiliary list(s)\n",
    "    if photon_loss != 0:\n",
    "        create_photon_loss(N, N) # used on the NxN circuit, equivalent to simulation on the m*m circuit as shown before\n",
    "    if method == \"pseudo PNR\" or method == \"post selection\":\n",
    "        create_pi_factors(N)\n",
    "    if method == \"threshold\" or method == \"pseudo PNR\":\n",
    "        create_threshold_indexes(m)\n",
    "        \n",
    "        \n",
    "    # Change here the value of alpha (must be parameterized)\n",
    "    global alpha\n",
    "    if samples == 0:\n",
    "        alpha = 0\n",
    "    else:\n",
    "        alpha = 0\n",
    "\n",
    "    \n",
    "    global fock_dim\n",
    "    global lambda_random\n",
    "    fock_dim = get_fock_dim(m, N, method)\n",
    "    # lambda coefficients for all the possible outputs\n",
    "    lambda_random = np.random.rand(fock_dim)\n",
    "    \n",
    "    # Normalise the distribution to avoid random impossible solving parameters\n",
    "    lambda_random = a * (lambda_random - np.mean(lambda_random)) / np.std(lambda_random)\n",
    "    \n",
    "    # dx serves for the numerical differentiation of f\n",
    "    global dx\n",
    "    # dx = (range_max-range_min) / 1000         # Used for first order finite difference\n",
    "\n",
    "    dx = (range_max-range_min)/(n_grid - 1)         # Used for second order finite difference, faster and more precise\n",
    "    \n",
    " \n",
    "    \n",
    "    \"Haar unitary parameters\"\n",
    "    # number of parameters used for the two universal interferometers (2*N**2 per interferometer) as initial guess\n",
    "    global parameters\n",
    "    parameters = np.random.normal(size=4*N2)\n",
    "     \n",
    "    # Make the initial guess unitary if there is imprecision (useful for relative step size)\n",
    "    if imprecision != 0:\n",
    "        A = pcvl.Matrix.random_unitary(N, parameters[:2 * N2])\n",
    "        parameters[:2 * N2] = np.concatenate((np.real(A).reshape((N2,)), np.imag(A).reshape((N2,))))\n",
    "        \n",
    "        A = pcvl.Matrix.random_unitary(N, parameters[2 * N2:4 * N2])\n",
    "        parameters[2 * N2:4 * N2] = np.concatenate((np.real(A).reshape((N2,)), np.imag(A).reshape((N2,))))\n",
    "      \n",
    "    \n",
    "    if method == \"real solving\":\n",
    "        parameters = np.concatenate((parameters, lambda_random))\n",
    "\n",
    "\n",
    "    # Just display the circuit, not used after\n",
    "    if display:\n",
    "        px = pcvl.P(\"px\")\n",
    "        c = (pcvl.Circuit(m)\n",
    "             // phys.Unitary(pcvl.Matrix.random_unitary(N, parameters[:2 * N2]), name=\"W1\")\n",
    "             // (0, phys.PS(px))\n",
    "             // phys.Unitary(pcvl.Matrix.random_unitary(N, parameters[2 * N2:4 * N2]), name=\"W2\"))\n",
    "\n",
    "        if method == \"pseudo PNR\" or method == \"post selection\":\n",
    "            c = construct_separators(c)\n",
    "  \n",
    "        pcvl.pdisplay(c)\n",
    "    \n",
    "    # It was temporary for the display and list creation, but it is needed that they become equal for what is next\n",
    "    m = N\n",
    "    \n",
    "    input_state = pcvl.BasicState([1]*N+[0]*(m-N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d45e36",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def initiate_optimisation():\n",
    "    # Variables set to record and monitor the optimisation\n",
    "    np.random.seed(int(10000*time.time()+os.getpid()) & 0xffffffff) #not necessary here, but when we run our program on several cores, this line allows us to generate different unit matrices at the same time.\n",
    "    global computation_count\n",
    "    computation_count = 0\n",
    "    \n",
    "    global current_loss\n",
    "    current_loss = 0\n",
    "    \n",
    "    global start_time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    global loss_evolution\n",
    "    loss_evolution = []\n",
    "    \n",
    "    global iteration_count\n",
    "    iteration_count = 1  # callback is at the end of each iteration in case of convergence not reached\n",
    "    \n",
    "    global total_computation_count\n",
    "    total_computation_count = 0\n",
    "        \n",
    "    if use_pbar_and_display:\n",
    "        global pbar\n",
    "        pbar = tqdm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88589d73",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28f1a4e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A generic function to compute the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed4d2f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_probs(circuit, input_state, method):\n",
    "\n",
    "    if not use_imperfect_source:\n",
    "        U = circuit.compute_unitary(use_symbolic=False)\n",
    "        s1.U = U\n",
    "        \n",
    "        probs = s1.all_prob(input_state)\n",
    "    else:\n",
    "        process = create_processor(source, circuit, [1]*N+[0]*(m-N))\n",
    "        probs = get_all_processor_probabilities(process)\n",
    "        \n",
    "        \n",
    "    if photon_loss != 0:\n",
    "        probs = compute_photon_loss(probs)\n",
    "    \n",
    "  \n",
    "    # Simulates a 2m circuit if needed\n",
    "    if method ==\"post selection\":\n",
    "        probs = calc_all_probs(probs)\n",
    "        \n",
    "    if method == \"threshold\":\n",
    "        probs = threshold_prob(probs)\n",
    "        \n",
    "    if method == \"pseudo PNR\":\n",
    "        probs = calc_PNR_probs(probs)\n",
    "    \n",
    "    # random observations according to the distribution\n",
    "    probs = get_samples(samples, probs)\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ead728",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc(circuit, input_state, coefs, method):\n",
    "    probs = get_probs(circuit, input_state, method)\n",
    "    \n",
    "    return np.sum(np.multiply(probs, coefs))        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b649e70",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Loss function in the case we are modifying the matrix parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8accd728",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def computation(params):\n",
    "    global current_loss\n",
    "    global computation_count\n",
    "    \"compute the loss function when the matrix parameters are being optimized\"\n",
    "    computation_count += 1\n",
    "\n",
    "    coefs = lambda_random  # coefficients of the M observable\n",
    "    # initial condition with the two universal interferometers and the phase shift in the middle\n",
    "    \n",
    "    if imprecision == 0:\n",
    "        U_1 = pcvl.Matrix.random_unitary(N, params[:2 * N2])\n",
    "        U_2 = pcvl.Matrix.random_unitary(N, params[2 * N2:4 * N2])\n",
    "        X_used = X\n",
    "        \n",
    "   \n",
    "    else:\n",
    "        U_1 = imprecise_matrix(params[:2 * N2], imprecision)\n",
    "        U_2 = imprecise_matrix(params[2 * N2:4 * N2], imprecision)\n",
    "        X_used = round_imprecision(X, imprecision)\n",
    "        \n",
    "\n",
    "    # Circuit creation\n",
    "    px = pcvl.P(\"px\")\n",
    "    c = (phys.Unitary(U_2)\n",
    "         // (0, phys.PS(px)) \n",
    "         // phys.Unitary(U_1))\n",
    "\n",
    "    \n",
    "    px.set_value(round_imprecision(x_0, imprecision))\n",
    "    f_theta_0 = calc(c, input_state, coefs, method)\n",
    "\n",
    "     \n",
    "    # boundary condition given a weight eta\n",
    "    loss = eta * (f_theta_0 - f_0) ** 2 * n_grid\n",
    "    \n",
    "        \n",
    "    # Warning : Y[0] is before the domain we are interested in (used for differentiation), the domain begins at Y[1]\n",
    "    Y = np.zeros(n_grid + 2)\n",
    "    \n",
    "    # Small optimisation working if x_0 == range_min\n",
    "    if x_0 == range_min:\n",
    "        Y[1] = f_theta_0\n",
    "        assigned = 1\n",
    "    else:\n",
    "        assigned = 0\n",
    "        \n",
    "    \n",
    "    px.set_value(round_imprecision(range_min - dx, imprecision))\n",
    "    Y[0] = calc(c, input_state, coefs, method)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(assigned, n_grid):\n",
    "        x = X_used[i]\n",
    "\n",
    "        px.set_value(x)\n",
    "        Y[i + 1] = calc(c, input_state, coefs, method)\n",
    "    \n",
    "    \n",
    "    # Y_prime[0] is the beginning of the domain /!\\ not the same for Y\n",
    "    px.set_value(round_imprecision(range_max + dx, imprecision)) \n",
    "    Y[n_grid + 1] = calc(c, input_state, coefs, method)\n",
    "    \n",
    "    \n",
    "    # Here is one problem that must be solved. \n",
    "    if samples != 0:\n",
    "        Y = noise_filter(Y)\n",
    "    \n",
    "    \n",
    "    # Or we can compute Y_prime by finite difference using Y and not dx\n",
    "    # The approximation is far better with a second order scheme\n",
    "    # This could be the fastest way to compute the derivative (or at least an approximation)\n",
    "\n",
    "    Y_prime = (Y[2:] - Y[:-2])/(2*dx)\n",
    "    \n",
    "    # This method is apparently the fastest to calculate the L2 norm squared\n",
    "    loss += np.sum((F(Y_prime, Y[1:-1], X))**2)\n",
    "        \n",
    "    \n",
    "    # Displayed\n",
    "    current_loss = loss / n_grid\n",
    "    \n",
    "    # Useless for this part of the optimisation, but useful to keep the same loss value\n",
    "    loss = current_loss + alpha * np.sum(coefs ** 2)\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34de5efc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Functions used to calculate the loss when minimizing via the ponderations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f08ef1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_final_probs(params):\n",
    "    \"\"\"\n",
    "    Gather all the probabilities at the points of the grid in a single object    \n",
    "    \"\"\"\n",
    "    \n",
    "    U_1 = imprecise_matrix(params[:2 * N2], imprecision)\n",
    "    U_2 = imprecise_matrix(params[2 * N2:4 * N2], imprecision)\n",
    "    X_used = round_imprecision(X, imprecision)\n",
    "\n",
    "    px = pcvl.P(\"px\")\n",
    "    c = (phys.Unitary(U_2)\n",
    "         // (0, phys.PS(px)) \n",
    "         // phys.Unitary(U_1))\n",
    "    \n",
    "\n",
    "    # probs[0] corresponds to x0, probs[1] to -dx, ..., probs[-1] to range_max + dx\n",
    "    probs = []\n",
    "    \n",
    "    px.set_value(round_imprecision(x_0, imprecision))\n",
    "    probs.append(get_probs(c, input_state, method))\n",
    "    \n",
    "    px.set_value(round_imprecision(range_min - dx, imprecision))\n",
    "    probs.append(get_probs(c, input_state, method))\n",
    "    \n",
    "    if x_0 == range_min:\n",
    "        probs.append(probs[0])\n",
    "        assigned = 1\n",
    "    else:\n",
    "        assigned = 0\n",
    "    \n",
    "    for i in range(assigned, n_grid):\n",
    "        x = X_used[i]\n",
    "\n",
    "        px.set_value(x)\n",
    "        probs.append(get_probs(c, input_state, method))\n",
    "\n",
    "        \n",
    "    px.set_value(round_imprecision(range_max + dx, imprecision))\n",
    "    probs.append(get_probs(c, input_state, method))\n",
    " \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bbf67e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def loss_from_ponderations(coefs):\n",
    "    \"\"\"\n",
    "    This is the loss function when optimizing the ponderations. Its result is the same than for the previous function\n",
    "    \"\"\"\n",
    "    global current_loss\n",
    "    f_theta_0 = np.sum(np.multiply(coefs, probs[0]))\n",
    "    \n",
    "    loss = eta * (f_theta_0 - f_0) ** 2 * n_grid\n",
    "    \n",
    "    Y = np.array([np.sum(np.multiply(coefs, probs[i])) for i in range(1, len(probs))])\n",
    "    \n",
    "    \n",
    "    # Here is one problem that must be solved. \n",
    "    if samples != 0:\n",
    "        Y = noise_filter(Y)\n",
    "    \n",
    "    Y_prime = (Y[2:] - Y[:-2])/(2*dx)\n",
    "    \n",
    "    # This method is apparently the fastest to calculate the L2 norm squared\n",
    "    loss += np.sum((F(Y_prime, Y[1:-1], X))**2)\n",
    "        \n",
    "    # Displayed\n",
    "    current_loss = loss / n_grid\n",
    "    \n",
    "    loss = current_loss + alpha * np.sum(coefs ** 2)\n",
    "    return loss    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a65f683",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The function to launch the computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac723aba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def callbackF(parameters):\n",
    "    \"\"\"callback function called by scipy.optimize.minimize allowing to monitor progress\"\"\"\n",
    "    global current_loss\n",
    "    global computation_count\n",
    "    global loss_evolution\n",
    "    global start_time\n",
    "    global iteration_count\n",
    "    \n",
    "    if step == \"circuit\":\n",
    "        iteration_count += 1    \n",
    "        \n",
    "    now = time.time()\n",
    "    if use_pbar_and_display:\n",
    "        pbar.set_description(\"N= %d Loss: %0.5f #computations: %d elapsed: %0.5f step: \" %\n",
    "                             (N, current_loss, computation_count, now-start_time) + step)\n",
    "        pbar.update(1)\n",
    "    loss_evolution.append((current_loss, now-start_time))\n",
    "    computation_count = 0\n",
    "    start_time = now\n",
    "    \n",
    "    if samples != 0 and not iteration_count % 5 and step == \"ponderations\":\n",
    "        # The distribution doesn't change here, we just want to avoid bias due to sampling\n",
    "        global probs\n",
    "        probs = get_all_samples(samples, all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb577ac8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_optimisation(param):\n",
    "    \"\"\"\n",
    "    input : param[tuple[(key1, value1, key2, value2...)]]\n",
    "    \n",
    "    output : list containing:\n",
    "    - the parameters to get the matrix\n",
    "    - the ponderations\n",
    "    - a list containing the loss and the computation time at each iteration\n",
    "    - the number of iterations during the matrix parameters optimization part\n",
    "    - the total number of distribution evaluation. Multiply this by the number of samples to know of many samples are required in total.\n",
    "    - the final loss. It might differ from the last loss of the previous list as if the circuit optimisation is worse than the ponderation part, results are saved from the ponderation part.\n",
    "    \"\"\"\n",
    "    param_dict = tuple_to_dict(param)\n",
    "\n",
    "    global all_results\n",
    "    initiate_optimisation()\n",
    "    initiate(param_dict, display = use_pbar_and_display)\n",
    "\n",
    "    global lambda_random\n",
    "    global parameters\n",
    "\n",
    "    global step\n",
    "\n",
    "    global probs\n",
    "\n",
    "    conv_crit = 1e-2\n",
    "    max_iter = 5\n",
    "\n",
    "    global all_probs\n",
    "\n",
    "    i = 1\n",
    "    while True:\n",
    "\n",
    "        all_probs = get_final_probs(parameters)\n",
    "\n",
    "        step = \"ponderations\"            \n",
    "        # Does nothing if samples = 0\n",
    "        probs = get_all_samples(samples, all_probs)\n",
    "        if samples != 0:\n",
    "            # Just add some boundaries to avoid huge values of lambda. However, BFGS doesn't support constraints. Impact still has to be evaluated\n",
    "            res2 = minimize(loss_from_ponderations, lambda_random, bounds = len(lambda_random)*[(-a, a)], callback=callbackF, method='L-BFGS-B', options={'gtol': 1E-5})\n",
    "        else:\n",
    "            res2 = minimize(loss_from_ponderations, lambda_random, callback=callbackF, method='BFGS', options={'gtol': 1E-5})\n",
    "\n",
    "        lambda_random = res2.x\n",
    "        error_ponderations = res2.fun - alpha * np.sum(lambda_random ** 2)\n",
    "\n",
    "        step = \"circuit\"\n",
    "\n",
    "        if samples != 0:\n",
    "            # This option can work sometimes \n",
    "            res = minimize(computation, parameters, callback=callbackF, method='COBYLA', options = {'rhobeg' : 1/(20 * np.sqrt(2*N))}) \n",
    "\n",
    "\n",
    "        elif imprecision != 0:\n",
    "            # Use epsilon relatively to the error\n",
    "            res = minimize(computation, parameters, callback=callbackF, method='BFGS', options={'gtol': 1E-2, 'eps' : 2 * imprecision})          \n",
    "\n",
    "        else:\n",
    "            # Use default epsilon = 1.4901161193847656e-08\n",
    "            res = minimize(computation, parameters, callback=callbackF, method='BFGS', options={'gtol': 1E-2})\n",
    "\n",
    "        error_circuit = res.fun  - alpha * np.sum(lambda_random ** 2)\n",
    "\n",
    "        if error_ponderations < error_circuit:\n",
    "            # We don't change the parameters then\n",
    "            final_loss = error_ponderations\n",
    "            break\n",
    "\n",
    "        parameters = res.x\n",
    "\n",
    "        if abs(error_ponderations - error_circuit) / error_ponderations < conv_crit or i == max_iter:\n",
    "            # In any case, the result is the one containing the circuit parameters\n",
    "            final_loss = error_circuit\n",
    "            break   \n",
    "\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    if method == \"real solving\":\n",
    "        lambda_random = res.x[4 * N2:]\n",
    "\n",
    "    # Save the results\n",
    "    return [parameters.copy(), lambda_random.copy(), loss_evolution.copy(), iteration_count, total_computation_count, final_loss]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c364db",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The launch of the computations itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f747fe6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if launch_single_computation:\n",
    "    # Initialisation of the results\n",
    "    # Can also be used to throw the previous results\n",
    "\n",
    "    all_results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c6e0d",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if launch_single_computation:\n",
    "    \n",
    "    use_pbar_and_display = True\n",
    "    \n",
    "    '''\n",
    "    Needed parameters are  and \"N\"\n",
    "    (\"method\", str) possible choices of method are \"real solving\", \"fixed ponderations\", \"pseudo PNR\", \"threshold\", and \"post selection\"\n",
    "    (\"N\", int) The number of photons. PNR and post selection use twice as much modes, other method have m = N\n",
    "       \n",
    "    Other parameters can be specified with \n",
    "    (\"brightness\", float[0:1]) 1 - the probability that a photon is not emitted at the source. Too slow to be used for now. Default : 1\n",
    "    (\"purity\", float[0:1]) 1 - the probability that 2 photons are emitted at the source. Too slow to be used for now. Default : 1\n",
    "    (\"photon loss\", float[0:1]) The probability that a photon is not detected. Default : 0\n",
    "    (\"imprecision\", float) The imprecision on the angles of your interferometer. Default : 0\n",
    "    (\"samples\", unsigned int) The number of samples used for evaluating the probability distribution. 0 gives the true distribution. Default : 0\n",
    "    '''\n",
    "    \n",
    "    params = [(\"method\", \"post selection\", \"N\", 6)]\n",
    "    for param in params:\n",
    "        if not param in all_results.keys():\n",
    "            all_results[param] = []\n",
    "    \n",
    "    \n",
    "    for param in params:     \n",
    "        all_results[param].append(run_optimisation(param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f43bfe1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Just verify that the results are the computed ones. Also useful to see how much noise we can expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaf4af3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(max(abs(lambda_random)))\n",
    "print(min(abs(lambda_random)))\n",
    "\n",
    "print(all_results[params[0]][-1][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793eb64d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805be21f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We first plot the graph of the solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca18e39e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_solution(X_plot, optim_params, lambda_random, param_dict):\n",
    "    # You have to run initiate before this one when you change your parameters \n",
    "    \n",
    "    N = param_dict[\"N\"]\n",
    "    N2 = N ** 2\n",
    "    method = param_dict[\"method\"]\n",
    "    imprecision = param_dict[\"imprecision\"]\n",
    "    Y = []\n",
    "    \n",
    "    U_1 = imprecise_matrix(optim_params[:2 * N2], imprecision)\n",
    "    U_2 = imprecise_matrix(optim_params[2 * N2:4 * N2], imprecision)\n",
    "\n",
    "    X_used = round_imprecision(X_plot, imprecision)\n",
    "    \n",
    "    px = pcvl.P(\"x\")\n",
    "    \n",
    "    c = phys.Unitary(U_2) // (0, phys.PS(px)) // phys.Unitary(U_1)\n",
    "    \n",
    "    \n",
    "    for x in X_used:\n",
    "        px.set_value(x)       \n",
    "        f_theta = calc(c, input_state, lambda_random, method)\n",
    "        Y.append(f_theta)\n",
    "    \n",
    "    #p = plt.plot(X_plot, Y, label=get_legend(param_dict))\n",
    "      \n",
    "    if samples != 0:\n",
    "        Y = noise_filter(Y)\n",
    "\n",
    "        #plt.plot(X_plot, Y, p[-1].get_color(), label = \"filtfilt\")\n",
    "    \n",
    "    p = plt.plot(X_plot, Y, label=get_legend(param_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80729d25",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_legend(param_dict, excluded = None):\n",
    "    \"\"\"\n",
    "    Creates the legend for your set of parameters. If one parameter is the default one, it doesn't appear.\n",
    "    \"\"\"  \n",
    "    default_values = tuple_to_dict(())\n",
    "    \n",
    "    if excluded != \"method\" and excluded != \"N\":\n",
    "        legend = f'{param_dict[\"method\"]} with {param_dict[\"N\"]} photons'\n",
    "    \n",
    "    if excluded == \"method\":\n",
    "        legend = f'{param_dict[\"N\"]} photons'\n",
    "        \n",
    "    if excluded == \"N\":\n",
    "        legend = f'{param_dict[\"method\"]}'\n",
    "           \n",
    "    key = \"imprecision\"\n",
    "    if excluded != key and param_dict[key] != default_values[key]:\n",
    "        legend += f' and {key} of {param_dict[key]} rad'\n",
    "    \n",
    "    key = \"samples\"\n",
    "    if excluded != key and param_dict[key] != default_values[key]:\n",
    "        legend += f' and {param_dict[key]} {key}'\n",
    "    \n",
    "    for key in [\"photon loss\", \"brightness\", \"purity\"]:\n",
    "        if excluded != key and param_dict[key] != default_values[key]:\n",
    "            legend += f' and a {key} of {param_dict[key] * 100}%'\n",
    "        \n",
    "    key = \"R\"\n",
    "    if excluded != key and key in param_dict.keys() and param_dict[key] != .5:\n",
    "        legend += f'and a reflexivity of {param_dict[key]}'\n",
    "\n",
    "    return legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ac850",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if launch_single_computation:\n",
    "    # Plot all approximations for given criteria\n",
    "\n",
    "    # Change the parameters to see here, leave empty for all the simulations\n",
    "    criteria = {\"N\" : 6}\n",
    "\n",
    "    X_plot = np.linspace(range_min, range_max, 200)\n",
    "\n",
    "    # Change the plot size\n",
    "    default_figsize = mpl.rcParamsDefault['figure.figsize']\n",
    "    mpl.rcParams['figure.figsize'] = [2 * value for value in default_figsize]\n",
    "    \n",
    "\n",
    "    for key in all_results.keys():\n",
    "        key_dict = tuple_to_dict(key)\n",
    "        if criteria.items() <= key_dict.items():\n",
    "            for solution in all_results[key]:    \n",
    "                #key_dict[\"imprecision\"] = 0           # turn this on to plot as if there was no imprecision     \n",
    "                initiate(key_dict, display = False)\n",
    "\n",
    "                plot_solution(X_plot, solution[0], solution[1], key_dict)\n",
    "\n",
    "    plt.plot(X_plot, u(X_plot), 'k', label='Analytical solution')\n",
    "    \n",
    "    #plt.title(str(criteria)[1:-1])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a6cbf3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then we plot the final loss for the different methods and number of photons, as well as the computation time and the total number of iterations. (beware some of the graphs are in log scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd8cce9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Functions to retrieve the data\n",
    "def get_losses(results):\n",
    "    losses = dict()\n",
    "    \n",
    "    for params in results.keys():\n",
    "        losses[params] = []\n",
    "        for solution in results[params]:\n",
    "            losses[params].append(solution[5])\n",
    "            \n",
    "    return losses\n",
    "\n",
    "\n",
    "def get_calc_times(results):\n",
    "    calc_times = dict()\n",
    "    \n",
    "    for params in results.keys():\n",
    "        calc_times[params] = []\n",
    "        for solution in results[params]:\n",
    "            calc_times[params].append(np.sum(np.array(solution[2])  / 60, axis = 0)[1])    # In minutes\n",
    "            \n",
    "    return calc_times\n",
    "\n",
    "\n",
    "def get_it_number(results):\n",
    "    it_number = dict()\n",
    "    \n",
    "    for params in results.keys():\n",
    "        it_number[params] = []\n",
    "        for solution in results[params]:\n",
    "            it_number[params].append(solution[3])\n",
    "            \n",
    "    return it_number\n",
    "\n",
    "\n",
    "def get_computation_count(results):\n",
    "    computation_count = dict()\n",
    "    \n",
    "    for params in results.keys():\n",
    "        computation_count[params] = []\n",
    "        for solution in results[params]:\n",
    "            computation_count[params].append(solution[4])\n",
    "            \n",
    "    return computation_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eecba84",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def acceptable(dict_key, allow_dict, forbid_dict):\n",
    "    if forbid_dict == None:\n",
    "        return allow_dict.items() <= dict_key.items()\n",
    "    else:\n",
    "        return allow_dict.items() <= dict_key.items() and not forbid_dict.items() <= dict_key.items()\n",
    "\n",
    "# Computes the mean and standard deviation\n",
    "def plot_statistics(results, y_axis, x_axis, allow_dict = dict(), forbid_dict = None, y_scale = \"default\"):\n",
    "    \"\"\"\n",
    "    x_axis takes any of the parameters\n",
    "    y_axis accepts one of \"loss\", \"computation time\", \"iteration number\", \"computation count\"\n",
    "    \"\"\"\n",
    "    # In any case, Y is a dictionnary of lists\n",
    "    if y_axis == \"loss\":\n",
    "        Y = get_losses(results)\n",
    "    elif y_axis == \"computation time\":\n",
    "        Y = get_calc_times(results)\n",
    "    elif y_axis == \"iteration number\":\n",
    "        Y = get_it_number(results)\n",
    "    elif y_axis == \"computation count\":\n",
    "        Y = get_computation_count(results)\n",
    "        \n",
    "        \n",
    "        \n",
    "    if x_axis == \"photons\":\n",
    "        x_axis_used = \"N\"\n",
    "    else: \n",
    "        x_axis_used = x_axis\n",
    "        \n",
    "    # Useful for log scale, must be changed\n",
    "    if forbid_dict == None and x_axis == \"imprecision\":\n",
    "        forbid_dict={\"imprecision\" : 0}\n",
    "        \n",
    "        \n",
    "    if x_axis_used == \"N\" or x_axis_used == \"samples\":\n",
    "        # Only integer ticks will be displayed\n",
    "        ax = plt.figure().gca()\n",
    "        ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True)) \n",
    "    \n",
    "    \n",
    "    # number of keys = number of tuples of parameters\n",
    "    nb_params = []\n",
    "    all_params = [0]\n",
    "    for key in results.keys():\n",
    "        x = tuple_to_dict(key)[x_axis_used]\n",
    "        key_dict = tuple_to_dict(key)\n",
    "        \n",
    "        if acceptable(key_dict, allow_dict, forbid_dict) and len(Y[key]):       \n",
    "            all_params.append(x)\n",
    "            nb_params.append(sum(1 for key2 in results.keys() if tuple_to_dict(key2)[x_axis_used] == x and acceptable(tuple_to_dict(key2), allow_dict, forbid_dict)))\n",
    "    \n",
    "    all_params = np.array(all_params)\n",
    "    all_params = np.sort(np.unique(all_params))\n",
    "    \n",
    "    n_params = max(nb_params)\n",
    "    if len(all_params) >= 2:\n",
    "        one_param_size = min(all_params[1:] - all_params[:-1])\n",
    "    else:\n",
    "        one_param_size = 1\n",
    "    \n",
    "    graph_step = one_param_size * (0.8 + 0.1/n_params)/n_params\n",
    "    width = one_param_size * 0.8 - (n_params - 1) * graph_step\n",
    "    \n",
    "    visited = []\n",
    "    X_ticks = []\n",
    "    \n",
    "    # Main loop\n",
    "    i = 0\n",
    "    for key in results.keys(): \n",
    "        key_dict = tuple_to_dict(key) \n",
    "        if not key in visited and acceptable(key_dict, allow_dict, forbid_dict):\n",
    "            \n",
    "            # We can now visit all keys having the same parameters other than x_axis\n",
    "            key_dict.pop(x_axis_used)\n",
    "            \n",
    "            X = []       # Created \"by hand\" because the order is important\n",
    "            \n",
    "            means = []\n",
    "            stds = []\n",
    "            \n",
    "            for cur_key in results.keys():\n",
    "                cur_key_dict = tuple_to_dict(cur_key)\n",
    "                \n",
    "                if key_dict.items() <= cur_key_dict.items() and acceptable(cur_key_dict, allow_dict, forbid_dict):\n",
    "                    visited.append(cur_key)\n",
    "                    \n",
    "                    if len(Y[cur_key]): # If there are computations\n",
    "                        means.append(np.mean(Y[cur_key]))\n",
    "                        stds.append(np.std(Y[cur_key]))\n",
    "                        \n",
    "                        X.append(cur_key_dict[x_axis_used])\n",
    "                        X_ticks.append(cur_key_dict[x_axis_used])\n",
    "                        \n",
    "            shift = i * graph_step + width/2 - 0.4 * one_param_size\n",
    "            plt.bar(np.array(X) + shift, means, yerr = stds, label = get_legend(key_dict, excluded = x_axis_used), width = width);\n",
    "            i += 1           \n",
    "\n",
    "    \n",
    "    plt.xlabel(x_axis);\n",
    "    if y_scale == \"default\":\n",
    "        if y_axis == \"loss\" or y_axis == \"computation time\" or y_axis == \"computation count\":\n",
    "            plt.yscale(\"log\")\n",
    "    else:\n",
    "        plt.yscale(y_scale)\n",
    "        \n",
    "    #plt.xscale(\"log\")  # Doesn't work; the width is bigger on the left\n",
    "        \n",
    "    plt.xticks(np.unique(X_ticks))\n",
    "    if y_axis == \"computation time\":\n",
    "        plt.ylabel(y_axis + \" (min)\")\n",
    "    else:\n",
    "        plt.ylabel(y_axis);\n",
    "    plt.title(\"means and standard deviation of \" + y_axis);\n",
    "    plt.grid(axis = 'y', linestyle = '--', linewidth = 0.7)\n",
    "    plt.legend();\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e224eb3e",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if launch_single_computation:\n",
    "\n",
    "    # Small graphs\n",
    "    default_figsize = mpl.rcParamsDefault['figure.figsize']\n",
    "    mpl.rcParams['figure.figsize'] = [1.5 * value for value in default_figsize]\n",
    "    \n",
    "    # Change here to see other things\n",
    "    x_axis = \"photon loss\"\n",
    "\n",
    "    plot_statistics(all_results, \"loss\", x_axis)\n",
    "    plot_statistics(all_results, \"computation time\", x_axis)\n",
    "    plot_statistics(all_results, \"iteration number\", x_axis)\n",
    "    plot_statistics(all_results, \"computation count\", x_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144fb74b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We are also interested to see what part of the loss is due to the initial condition and what part is from the respect of the DE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe35c632",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss_parts(optim_params, lambda_random, total_loss, param_dict):\n",
    "    method = param_dict[\"method\"]\n",
    "    imprecision = param_dict[\"imprecision\"]\n",
    "    U_1 = imprecise_matrix(optim_params[:2 * N2], imprecision)\n",
    "    U_2 = imprecise_matrix(optim_params[2 * N2:4 * N2], imprecision)\n",
    "    px = pcvl.P(\"x\")\n",
    "    \n",
    "    c = phys.Unitary(U_2) // (0, phys.PS(px)) // phys.Unitary(U_1)\n",
    "           \n",
    "    px.set_value(round_imprecision(x_0, imprecision))         \n",
    "     \n",
    "    f_theta_0 = calc(c, input_state, lambda_random, method)\n",
    "    \n",
    "    loss_boundary = eta * (f_theta_0 - f_0) ** 2\n",
    "    \n",
    "    return loss_boundary, total_loss - loss_boundary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_all_loss_parts(results):\n",
    "    losses = get_losses(results)\n",
    "    detailled_losses = dict()\n",
    "    \n",
    "    global method\n",
    "    for params in results.keys():\n",
    "        param_dict = tuple_to_dict(params)\n",
    "            \n",
    "        detailled_losses[params] = []\n",
    "        \n",
    "        for solution in results[params]: \n",
    "            \n",
    "            initiate(param_dict, display = False)\n",
    "\n",
    "            detailled_losses[params].append(get_loss_parts(solution[0], solution[1], solution[5], param_dict))\n",
    "            \n",
    "    return detailled_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ab557",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_photon_range(results, selection_dict):\n",
    "    aux = [tuple_to_dict(key)['N'] for key in results.keys() if selection_dict.items() <= tuple_to_dict(key).items()]\n",
    "    \n",
    "    n_min = min(aux)\n",
    "    n_max = max(aux)\n",
    "    \n",
    "    return n_min, n_max\n",
    "\n",
    "\n",
    "def get_best_solutions(results):\n",
    "\n",
    "    best_solutions = dict()\n",
    "\n",
    "    for key in results.keys():\n",
    "        if results[key] != []:\n",
    "            best_solutions[key] = min((l, i) for (i, l) in enumerate(solution[5] for solution in results[key]))\n",
    "            \n",
    "    return best_solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8033ab7",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_decomposed_loss(results):\n",
    "\n",
    "    visited = []\n",
    "    \n",
    "    best_solutions = get_best_solutions(results)\n",
    "\n",
    "    for key in results.keys():\n",
    "        dict_key = tuple_to_dict(key)\n",
    "\n",
    "        if not key in visited:\n",
    "            key_without_N = dict_key.copy()\n",
    "            key_without_N.pop('N')\n",
    "            \n",
    "            n_min, n_max = get_photon_range(results, key_without_N)\n",
    "            nphotons = range(n_min, n_max + 1)\n",
    "\n",
    "            Y = np.zeros((n_max - n_min + 1, 2)) \n",
    "            for i in range(n_max - n_min + 1):\n",
    "\n",
    "                initiate(dict_key, display = False)\n",
    "\n",
    "                N_index = key.index('N') + 1\n",
    "                cur_key = list(key)\n",
    "                cur_key[N_index] = nphotons[i]\n",
    "                cur_key = tuple(cur_key)\n",
    "\n",
    "                visited.append(cur_key)\n",
    "                \n",
    "                if len(results[cur_key]):\n",
    "                    best_index = best_solutions[cur_key][1]\n",
    "                    solution = results[cur_key][best_index]\n",
    "\n",
    "                    initiate(tuple_to_dict(cur_key), display = False)\n",
    "\n",
    "                    Y[i, :] = get_loss_parts(solution[0], solution[1], solution[5], tuple_to_dict(cur_key))\n",
    "\n",
    "\n",
    "            boundary_loss = Y[:, 0]\n",
    "            DE_loss = Y[:, 1]\n",
    "\n",
    "            plt.bar(np.array(nphotons) - 0.2, boundary_loss, label = \"boundary loss\", width=0.3);\n",
    "            plt.bar(np.array(nphotons) + 0.2, DE_loss, label = \"Differential equation loss\", width=0.3);\n",
    "\n",
    "            plt.xlabel(\"nb of photons\");\n",
    "            plt.ylabel(\"Loss\");\n",
    "            plt.yscale(\"log\")            \n",
    "            plt.title(\"Separated loss for \" + get_legend(dict_key));\n",
    "            plt.legend();\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce54a866",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if launch_single_computation:\n",
    "    # May take some time to plot all the graphs if there are many different sets of parameters\n",
    "    plot_decomposed_loss(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad5af6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Multiple runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd0cdd1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To run multiple (hundreds) times the simulation to make statistics, a dataframe should be more convenient than a dictionnary. However, since the size of the lambda parameters is not fixed, we cannot use pandas, which doesn't support lists as values. We store our results in files, with one file containing one experiment and the name of the folder telling the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb491e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_parameter(directory, key, default_values, param_dict):\n",
    "    \n",
    "    if key in param_dict.keys() and param_dict[key] != default_values[key]:\n",
    "        directory += f\"_{key}:{param_dict[key]}\"\n",
    "    \n",
    "    return directory\n",
    "\n",
    "\n",
    "def get_directory_name(param_dict):\n",
    "    \"\"\" Function used to always have the keys in the same order in the folder's name;\n",
    "    otherwise, N:_method:_ would lead to a different key than method:_N: while being equivalent\n",
    "    \n",
    "    A key doesn't appear if its value is the default one. This is to allow the adding of new keys.\n",
    "    \n",
    "    Chosen order : method, N, brightness, purity, photon loss, imprecision, samples\n",
    "    \"\"\"\n",
    "    \n",
    "    directory = f\"./Results/N:{param_dict['N']}_method:{param_dict['method']}\"\n",
    "    \n",
    "    default_values = tuple_to_dict(())\n",
    "    \n",
    "    \n",
    "    keys = ['brightness', 'purity', 'photon loss', 'imprecision', 'samples']\n",
    "    for key in keys:\n",
    "        directory = add_parameter(directory, key, default_values, param_dict)\n",
    "        \n",
    "    \n",
    "    return directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4bf816",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The name of the parameters is necessarily weird to put them as global variables after\n",
    "def run_optimisation_parallel(param):\n",
    "    # Run a single optimisation using the parameters \n",
    "    solution = run_optimisation(param)\n",
    "    \n",
    "    # We now dump the result into a file, creating a folder if necessary\n",
    "    param_dict = tuple_to_dict(param)\n",
    "    directory = get_directory_name(param_dict)\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(directory)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    i = len(os.listdir(directory)) + 1\n",
    "    with open(directory + f\"/{i}.pkl\", 'wb') as f:\n",
    "        pickle.dump(solution, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791ab4ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Launch the computation.\n",
    "The results will stack up with the older ones.\n",
    "Consider running the cell two places above if you want to clean up the old results.\n",
    "\n",
    "Sometimes, the progress bar acts weird and stops two iterations before the end, even if all is finished.\n",
    "'''\n",
    "\n",
    "\n",
    "# Redefined here in case we just want to run some cases but keep the previous results\n",
    "methods = [\"fixed ponderations\", \"pseudo PNR\", \"post selection\"]\n",
    "nphotons = [n for n in range(2, 7)]\n",
    "photon_losses = [p_loss for p_loss in np.arange(0, 0.55, 0.05)]\n",
    "    \n",
    "one_iteration = [(\"method\", method, \"N\", n, \"photon loss\", p_loss) for method in methods for n in nphotons for p_loss in photon_losses]\n",
    "        \n",
    "# Defines how much computations for each tuple of parameters will be performed\n",
    "iteration_number = 50\n",
    "\n",
    "\n",
    "# Allow computations to be done without interruption at the end of each cycle as if would be if it was done with a for loop\n",
    "all_parameters_iterated = iteration_number * one_iteration\n",
    "\n",
    "imax = len(all_parameters_iterated)\n",
    "\n",
    "# Toggles display of the circuit and run by run off to avoid spam. Instead, we show how much computations have been done\n",
    "use_pbar_and_display = False\n",
    "pbar = tqdm(total = imax)\n",
    "\n",
    "\n",
    "# It's useless to allocate more processes than the number of computations\n",
    "process_count = min(os.cpu_count(), imax)\n",
    "\n",
    "\n",
    "def parallel_run():\n",
    "    # The with command is used so the pool is automatically closed at the end of the computation\n",
    "    # By default, all the processors of the computer are used\n",
    "    with multiprocessing.Pool(process_count) as pool:\n",
    "\n",
    "        results = [pool.apply_async(run_optimisation_parallel, parameters) for parameters in all_parameters_iterated]\n",
    "        \n",
    "        pbar.update(1)\n",
    "        for i in range(imax):\n",
    "            pbar.set_description(f\"Now waiting for process with {all_parameters_iterated[i]}\")\n",
    "            pbar.update(1)\n",
    "            # Tested : processes always run; no pause; the program waits here if necessary while further results are calculated\n",
    "            results[i].get()\n",
    "            \n",
    "    \n",
    "    \n",
    "# Needed to avoid children process to create new children        \n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        os.mkdir(\"./Results\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    parallel_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e02a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the results from the files\n",
    "\n",
    "def change_type(key, value):\n",
    "    if key in ['N', 'samples']:\n",
    "        return int(value)\n",
    "    \n",
    "    if key in [\"imprecision\", 'brightness', 'purity', 'photon loss']:\n",
    "        return float(value)\n",
    "    \n",
    "    else:\n",
    "        # value must be a str\n",
    "        return value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_results_parallel = dict()\n",
    "\n",
    "for directory in os.listdir(\"./Results\"):\n",
    "    if directory != \".ipynb_checkpoints\":\n",
    "        \n",
    "        str_key = directory.split(\"_\")\n",
    "        \n",
    "        keys = []\n",
    "        \n",
    "        for key_value in str_key:\n",
    "            [key, value] =  key_value.split(\":\")\n",
    "            value = change_type(key, value)\n",
    "            keys.append(key)\n",
    "            keys.append(value)\n",
    "                \n",
    "        keys = tuple(keys)\n",
    "        all_results_parallel[keys] = []\n",
    "        for file in os.listdir(\"./Results/\" + directory):\n",
    "            with open(\"./Results/\" + directory + \"/\" + file, \"rb\") as f:\n",
    "                all_results_parallel[keys].append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6d95aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(tuple_to_dict(list(all_results_parallel.keys())[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d22c63c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bced063",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Show the total number of computations in the dictionnary given \n",
    "def get_number_of_computation(results, x_axis, selection_dict):\n",
    "    if x_axis == \"photons\":        \n",
    "        n_min, n_max = get_photon_range(results, selection_dict)\n",
    "        x_axis_key = \"N\"\n",
    "    \n",
    "    nb = (n_max - n_min + 1) * [0]\n",
    "    for key in all_results_parallel.keys(): \n",
    "        dict_key = tuple_to_dict(key)\n",
    "        if selection_dict.items() <= dict_key.items():\n",
    "            nb[dict_key[x_axis_key] - n_min] = len(results[key])\n",
    "    \n",
    "    return nb\n",
    "\n",
    "\n",
    "print(\"Total number of simulations :\", sum(get_number_of_computation(all_results_parallel, \"photons\", {\"method\" : \"post selection\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d4b34",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Plot all solutions having loss < loss_max.** Do not put loss_max huge if there are many results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c90f26e",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot all approximations having a loss inferior to loss_max\n",
    "\n",
    "loss_max = 0.015\n",
    "\n",
    "use_imperfect_source = False\n",
    "total_computation_count = 0\n",
    "\n",
    "X_plot = np.linspace(range_min, range_max, 200)\n",
    "\n",
    "simulator_backend = pcvl.BackendFactory().get_backend(\"SLOS\")\n",
    "\n",
    "\n",
    "def plot_all_solutions(solution_dictionnary, loss_max, legend = True):\n",
    "    \n",
    "    # Change the plot size\n",
    "    default_figsize = mpl.rcParamsDefault['figure.figsize']\n",
    "    mpl.rcParams['figure.figsize'] = [2 * value for value in default_figsize]\n",
    "    \n",
    "    \n",
    "    global N\n",
    "    global method\n",
    "\n",
    "    for key in solution_dictionnary.keys():\n",
    "        dict_key = tuple_to_dict(key)\n",
    "        \n",
    "        initiated = False\n",
    "        \n",
    "        for solution in solution_dictionnary[key]: \n",
    "\n",
    "            # Select good enough results (avoid graph compacting)\n",
    "            if solution[5] <= loss_max:\n",
    "                \n",
    "                if not initiated:                \n",
    "                    initiate(dict_key, display = False)\n",
    "                    initiated = True\n",
    "\n",
    "                plot_solution(X_plot, solution[0], solution[1], dict_key)\n",
    "\n",
    "\n",
    "    plt.plot(X_plot, u(X_plot), 'k', label='Analytical solution')\n",
    "    plt.title(\"Solutions with loss inferior to %0.3g\" % loss_max)\n",
    "    if legend:\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_all_solutions(all_results_parallel, loss_max, legend = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05061edf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We then want to find for each key the best solution (in term of loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd38b66",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_solutions = get_best_solutions(all_results_parallel)\n",
    "# print(best_solutions)\n",
    "\n",
    "\n",
    "# We now plot all the best solutions\n",
    "\n",
    "# It is possible to ask only one method\n",
    "methods_to_plot = \"all\"\n",
    "#methods_to_plot = [\"pseudo PNR\", \"post selection\"]\n",
    "\n",
    "# Or the number of photons from which the curves have to be plot\n",
    "min_photons = 6\n",
    "\n",
    "default_figsize = mpl.rcParamsDefault['figure.figsize']\n",
    "mpl.rcParams['figure.figsize'] = [2 * value for value in default_figsize]\n",
    "\n",
    "\n",
    "for key in best_solutions.keys():\n",
    "    dict_key = tuple_to_dict(key)\n",
    "    \n",
    "    if dict_key['N'] >= min_photons:\n",
    "\n",
    "        if methods_to_plot == \"all\" or dict_key['method'] in methods_to_plot:\n",
    "            \n",
    "            best_index = best_solutions[key][1]\n",
    "            solution = all_results_parallel[key][best_index]\n",
    "\n",
    "            # Select good enough results (avoid graph compacting)\n",
    "\n",
    "            initiate(dict_key, display = False)\n",
    "\n",
    "            plot_solution(X_plot, solution[0], solution[1], dict_key)\n",
    "\n",
    "plt.plot(X_plot, u(X_plot), 'k', label='Analytical solution')\n",
    "plt.title(method)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715265fe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now plot the boundary loss and the DE loss for the best solution in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb73e9",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Small graphs\n",
    "default_figsize = mpl.rcParamsDefault['figure.figsize']\n",
    "mpl.rcParams['figure.figsize'] = [1 * value for value in default_figsize]\n",
    "\n",
    "plot_decomposed_loss(all_results_parallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6f1009",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Statistics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c631be",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We are now interested in finding the mean and the standard deviation for each set of parameters for both the selected computations and the global ones, relatively to the computation time, the number of iterations and the total number of computations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c856655",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First with all computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec41529",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Small graphs\n",
    "default_figsize = mpl.rcParamsDefault['figure.figsize']\n",
    "mpl.rcParams['figure.figsize'] = [1.5 * value for value in default_figsize]\n",
    "\n",
    "\n",
    "methods = \"all\"\n",
    "#methods = [\"pseudo PNR\", \"post selection\"]\n",
    "\n",
    "\n",
    "\n",
    "plot_statistics(all_results_parallel, \"loss\", \"photons\")\n",
    "plot_statistics(all_results_parallel, \"computation time\", \"photons\")\n",
    "plot_statistics(all_results_parallel, \"iteration number\", \"photons\")\n",
    "plot_statistics(all_results_parallel, \"computation count\", \"photons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02016cc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now with selections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae6258d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can select the closest to the best approximation solutions so we can see what method gives us good results the more frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5221aa09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def select_good_approximations(results, epsilon, return_selected = False):\n",
    "    # If return_selected == True, then all solutions having a loss less than epsilon*min(loss) are returned, as well as the best loss\n",
    "    # Else, it returns the number of solutions having a loss less than epsilon*min(loss)\n",
    "    \n",
    "    best_solutions = get_best_solutions(results)\n",
    "    \n",
    "    best_of_all = min((best_solutions[key], key) for key in best_solutions.keys()) # Tuple ((loss, index), (method, N[, brightness]))\n",
    "    \n",
    "    good_approximations = dict()\n",
    "    \n",
    "    for key in best_solutions.keys():\n",
    "        good_approximations[key] = []\n",
    "        \n",
    "        for solution in results[key]:\n",
    "            if solution[5] <= best_of_all[0][0] * epsilon:\n",
    "                good_approximations[key].append(solution)\n",
    "    \n",
    "    if return_selected:\n",
    "        return good_approximations, best_of_all\n",
    "    else:\n",
    "        return sum([len(good_approximations[key]) for key in good_approximations.keys()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43964016",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Here we obtain for each parameters the proportion that is close enough to the best approximation.\n",
    "\n",
    "methods = [\"real solving\", \"fixed ponderations\", \"threshold\", \"post selection\", \"pseudo PNR\"]\n",
    "\n",
    "\n",
    "epsilon = 5  # > 1\n",
    "# The plot doesn't always cover all the selected solutions, as there could be too many plots to do\n",
    "plot_epsilon = min(2, epsilon)\n",
    "\n",
    "\n",
    "# best : Tuple ((loss, index), (method, N[, brightness]))\n",
    "good_approximations, best = select_good_approximations(all_results_parallel, epsilon, return_selected = True)\n",
    "print(\"Minimal loss found : %0.3g\" % best[0][0], \"with a\", best[1][0], \"method\")\n",
    "print(\"Number of retained solutions :\", sum([len(good_approximations[key]) for key in good_approximations.keys()]))\n",
    "\n",
    "#plot_all_solutions(good_approximations, best[0][0] * plot_epsilon, legend = False)\n",
    "\n",
    "\n",
    "# Change the plot size\n",
    "default_figsize = mpl.rcParamsDefault['figure.figsize']\n",
    "mpl.rcParams['figure.figsize'] = [0.5 * value for value in default_figsize]\n",
    "\n",
    "\n",
    "x_axis = \"photons\"\n",
    "\n",
    "\n",
    "for method in methods:\n",
    "    proportion = np.array(get_number_of_computation(good_approximations, x_axis, {\"method\" : method})) \\\n",
    "    / np.array(get_number_of_computation(all_results_parallel, x_axis, {\"method\" : method}))\n",
    "    \n",
    "    \n",
    "    if x_axis == \"photons\":\n",
    "        n_min, n_max = get_photon_range(all_results_parallel, {\"method\" : method})\n",
    "        X = range(n_min, n_max + 1)\n",
    "    \n",
    "\n",
    "    plt.bar(X, proportion);\n",
    "    plt.ylim([0, 1.1])\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.title(\"Proportion of solutions with \" + str(epsilon) + \" times the loss of the best with \" + method)\n",
    "    plt.grid(axis = 'y', linestyle = '--', linewidth = 0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e48f6",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Small graphs\n",
    "default_figsize = mpl.rcParamsDefault['figure.figsize']\n",
    "mpl.rcParams['figure.figsize'] = [1.5 * value for value in default_figsize]\n",
    "\n",
    "methods = \"all\"\n",
    "#methods = [\"post selection\", \"pseudo PNR\"]\n",
    "\n",
    "\n",
    "plot_statistics(good_approximations, \"loss\", \"photons\", methods = methods, scale = \"linear\")\n",
    "plot_statistics(good_approximations, \"computation time\", \"photons\", methods = methods)\n",
    "plot_statistics(good_approximations, \"iteration number\", \"photons\", methods = methods)\n",
    "plot_statistics(good_approximations, \"computation count\", \"photons\", methods = methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d58175",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A last kind of selection could be interesting: we want to have the N best solutions for each parameter set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e4127",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def select_N_good_approximations(N, results):\n",
    "    # The N best solutions for each parameter set are returned\n",
    "       \n",
    "    good_N_approximations = dict()\n",
    "    \n",
    "    for key in best_solutions.keys():\n",
    "        good_N_approximations[key] = []\n",
    "        \n",
    "        i = 0\n",
    "        for solution in sorted(results[key], key = lambda sol: sol[5]):\n",
    "            if i < N:\n",
    "                good_N_approximations[key].append(solution)\n",
    "            else:\n",
    "                break\n",
    "            i += 1\n",
    "                \n",
    "    return good_N_approximations\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891979da",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "\n",
    "good_N_approximations = select_N_good_approximations(N, all_results_parallel)\n",
    "\n",
    "\n",
    "# Small graphs\n",
    "default_figsize = mpl.rcParamsDefault['figure.figsize']\n",
    "mpl.rcParams['figure.figsize'] = [1.5 * value for value in default_figsize]\n",
    "\n",
    "\n",
    "methods = \"all\"\n",
    "#methods = [\"post selection\", \"pseudo PNR\"]\n",
    "\n",
    "\n",
    "\n",
    "plot_statistics(good_N_approximations, \"loss\", \"photons\", methods = methods)\n",
    "plot_statistics(good_N_approximations, \"computation time\", \"photons\", methods = methods)\n",
    "plot_statistics(good_N_approximations, \"iteration number\", \"photons\", methods = methods)\n",
    "plot_statistics(good_N_approximations, \"computation count\", \"photons\", methods = methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9bede0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb8cbe4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb7d194",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Add the possibility to specify the reflexivity $R$ in the case of pseudo PNR and post selection.\n",
    "\n",
    "Add the possibility to specify the penalisation coefficient $\\alpha$ in the case of sampling.\n",
    "\n",
    "Add the possibility to specify the order and the cut frequency in the case of sampling.\n",
    "\n",
    "For all of these, add an easy way to implement parameters that are used only if there are particular other parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495b647d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb6f3b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Find a solution to make the minimisation converging in case of sampling (tested : noise reduction on $f$)\n",
    "\n",
    "Ideas : \n",
    "- Exact computation of $f'$ (difficulty : easy, but could require a lot of computing power)\n",
    "- Exact computation of the gradient for the matrix parameters (difficulty : very hard)\n",
    "- Exact computation of the gradient for the lambda coefficients (difficulty : medium)\n",
    "\n",
    "The parameters of the noise reduction have to be better tested, or other methods for noise reduction could be used.\n",
    "Also, the effect of imposing boundaries on $\\lambda$ must be evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaba3e9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Add a parameter for the minimum number of modes in case of a post selection.\n",
    "Maybe the way *pi_factors* is defined will not work anymore in this case and we would need to perform both the threshold and the pi_factors calculus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85224bfb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some results about derivation :\n",
    "\n",
    "$$\n",
    "loss = \\sum_x F(f'(x), f(x), x)^2 + \\alpha \\lVert \\lambda \\rVert ^2 + \\eta (f(x_0) - f_0)^2\n",
    "$$\n",
    "\n",
    "So for a particular $\\lambda_i$,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial loss}{\\partial \\lambda_i} = 2 \\sum_x F(f'(x), f(x), x) \\frac{\\partial F(f'(x), f(x), x)}{\\partial \\lambda_i} + 2 \\alpha \\lambda_i + 2 \\eta (f(x_0) - f_0) \\frac{\\partial f(0)}{\\partial \\lambda_i}\n",
    "$$\n",
    "\n",
    "And\n",
    "\n",
    "$$\n",
    "\\frac{\\partial F(f'(x), f(x), x)}{\\partial \\lambda_i} = \\frac{\\partial F}{\\partial f'} \\frac{\\partial f'}{\\partial \\lambda_i} + \\frac{\\partial F}{\\partial f} \\frac{\\partial f}{\\partial \\lambda_i} + \\frac{\\partial F}{\\partial x} \\frac{\\partial x}{\\partial \\lambda_i}\n",
    "$$\n",
    "\n",
    "So \n",
    "\n",
    "$$\n",
    "\\frac{\\partial F(f'(x), f(x), x)}{\\partial \\lambda_i} \\approx \\frac{\\partial F}{\\partial f'} \\frac{p_i(x + \\Delta x) - p_i(x - \\Delta x)}{2 \\Delta x}+ \\frac{\\partial F}{\\partial f} p_i(x)\n",
    "$$\n",
    "\n",
    "Furthermore,\n",
    "$$\n",
    "\\frac{\\partial f(x_0)}{\\partial \\lambda_i} = p_i(x_0)\n",
    "$$\n",
    "\n",
    "And in our case, $\\frac{\\partial F}{\\partial f'} = 1$\n",
    "\n",
    "and $\\frac{\\partial F}{\\partial f} = \\lambda (\\kappa + \\tan (\\lambda x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d5a36a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f30308f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generalise to all kind of DE:\n",
    "- multivariable\n",
    "- vector outputs\n",
    "- More orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ec49f8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b88dcbd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Make the plot_statistics function work with log scale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}